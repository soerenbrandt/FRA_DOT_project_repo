{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------#\n",
    "# Prepare datasets for ML\n",
    "#------------------------------------------------------------#\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "# Load datasets from CSV\n",
    "#------------------------------------------------------------#\n",
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets for ML\n",
    "### Train-Test-split\n",
    "Performs a randomized split of a dataset into a training- and test-set for each individual class (key) in the dataset.\n",
    "\n",
    "```train_test_split(dataset, test_size = 1/2.5, seed = 0)```\n",
    "- dataset: ```dict([<class>, <list of IDs>)])```\n",
    "- test_size: fraction of test-set to training-set (default: 40%)\n",
    "- seed: starting seed for random.sample function (default: 0)\n",
    "\n",
    "returns ```(dict([(<class>, <list of IDs>)]),...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, test_size = 1/2.5, seed = 0):\n",
    "    # set seed of random function\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # create training set and test set\n",
    "    exp_set_train = OrderedDict()\n",
    "    exp_set_test = OrderedDict()\n",
    "    \n",
    "    for chem, values in dataset.items():\n",
    "        # determine test set length and sample random experiments\n",
    "        test_len = int(len(values)*test_size)\n",
    "        test_ind = random.sample(range(0,len(values)), test_len)\n",
    "        \n",
    "        # sort test and training sets by classes\n",
    "        exp_set_test[chem] = [values[ind] for ind in test_ind]\n",
    "        exp_set_train[chem] = [values[ind] for ind in list(set(range(0,len(values)))  - set(test_ind))]\n",
    "        \n",
    "    return (exp_set_train, exp_set_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort experimental data by set\n",
    "Sort experimental data into training- and test-sets based on datasets obtained by train_test_split.\n",
    "\n",
    "```sort_by_set(exp_data, *sets)```\n",
    "- exp_data: ```dict([(<experiment ID>, <data array>)])```\n",
    "- sets: sequence of datasets as ```dict([(<class>, <list of IDs>)])```\n",
    "\n",
    "returns ```[[data_set1],[labels_set1],...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_set(exp_data, *sets):\n",
    "    # create empty dictionaries\n",
    "    sorted_dataset = []\n",
    "    for dataset in sets:\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for chem, set_numbers in dataset.items():\n",
    "            for num in set_numbers:\n",
    "                data.append(exp_data[num]/np.sqrt(np.sum(exp_data[num]**2)))\n",
    "                labels.append(chem)\n",
    "\n",
    "        sorted_dataset.append(data)\n",
    "        sorted_dataset.append(labels)\n",
    "        \n",
    "    return sorted_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental data from CSV files\n",
    "Loads data from a CSV file containing x-values in column one and y-values in column 2 and beyond.\n",
    "\n",
    "##### CSV format:\n",
    "|  x  | y_1 | y_2 | ... |\n",
    "|----|-----|-----|-----|\n",
    "|  0  |  $a_1$ |  $b_1$ |  |\n",
    "| ... | ... | ... | |\n",
    "|  n  | $a_n$ | $b_n$ | |\n",
    "\n",
    "Files should be labeled in the format: 000006.csv\n",
    "\n",
    "\n",
    "```load_set_from_CSV(exp_set, folder='../exp_csv')```\n",
    "- exp_set: ```dict([(<class>, <[experiment IDs]>)])```\n",
    "- folder (optional): folder string containing experimental files (default: '../exp_csv')\n",
    "\n",
    "returns ```(dict([(<ID>, <np.array(exp_data)>]), dict([(<ID>, <class>]), exp_set_size)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set_from_CSV(exp_set, folder='../exp_csv'):\n",
    "    # prepare dictionaries to reference data\n",
    "    exp_data = {}\n",
    "    exp_num_chem = {}\n",
    "\n",
    "    # start toolbar\n",
    "    sys.stdout.write(\"Loading experimental data \\n\")\n",
    "    sys.stdout.flush()\n",
    "    loaded = 0\n",
    "\n",
    "    for count, chem in enumerate(exp_set):\n",
    "        nums = exp_set[chem]\n",
    "\n",
    "        #loads image then normalizes data\n",
    "        datas = []\n",
    "        for b,num in enumerate(nums):\n",
    "            data = pd.read_csv(folder + \"/%06d.csv\" % (num)) # load data from file\n",
    "            data_spectra = (data.values[:,1:]-np.min(data.values[:,1:])).transpose()\n",
    "            datas.append(data_spectra)\n",
    "\n",
    "            # update the bar\n",
    "            sys.stdout.write('\\r')\n",
    "            bar = ((b+1)*100)/len(nums)\n",
    "            # the exact output you're looking for:\n",
    "            sys.stdout.write(str(chem) + \": [%-20s] %d%%\" % ('='*int(bar/5-1) + str(int(bar % 10)), bar))\n",
    "            sys.stdout.flush()\n",
    "            loaded += 1\n",
    "        \n",
    "        #saves the data in the dictionary\n",
    "        for n,num in enumerate(nums):\n",
    "            exp_data[num] = datas[n]\n",
    "            exp_num_chem[num] = chem\n",
    "            \n",
    "        # update the bar\n",
    "        sys.stdout.write(\"   \" + str(count+1) + \"/\" + str(len(exp_set)) + \" complete\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    exp_set_size = loaded\n",
    "    print(\"Length of experimental set loaded: \" + str(exp_set_size))\n",
    "\n",
    "    return (exp_data, exp_num_chem, exp_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental images from CSV files\n",
    "Loads 2-dimensional data into a resized image from a CSV file containing x-values in column one and y-values in column 2 and beyond. This is useful when using convolutional neural networks (CNNs).\n",
    "\n",
    "##### CSV format:\n",
    "|  x  | y_1 | y_2 | ... |\n",
    "|----|-----|-----|-----|\n",
    "|  0  |  $a_1$ |  $b_1$ |  |\n",
    "| ... | ... | ... | |\n",
    "|  n  | $a_n$ | $b_n$ | |\n",
    "\n",
    "Files should be labeled in the format: 000006.csv\n",
    "\n",
    "\n",
    "```load_images_from_CSV(exp_set, dim = (299,299), folder='../exp_csv')```\n",
    "- exp_set: ```dict([(<class>, <[experiment IDs]>)])```\n",
    "- dim: dimension of the resized image (default: (299,299)\n",
    "- folder (optional): folder string containing experimental files (default: '../exp_csv')\n",
    "\n",
    "returns ```(np.array(exp_images), np.array(labels), exp_set_size)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_CSV(exp_set, dim = 299, folder='../exp_csv'):\n",
    "    # prepare dictionaries to reference data\n",
    "    exp_images = {}\n",
    "    exp_data = {}\n",
    "    exp_num_chem = {}\n",
    "\n",
    "    # prepare arrays to story data\n",
    "    train_data = []\n",
    "    train_im = []\n",
    "    labels = []\n",
    "    exp_num = []\n",
    "\n",
    "    # start toolbar\n",
    "    sys.stdout.write(\"Loading experimental data \\n\")\n",
    "    sys.stdout.flush()\n",
    "    loaded = 0\n",
    "\n",
    "    for count, chem in enumerate(exp_set):\n",
    "        nums = exp_set[chem]\n",
    "\n",
    "        #loads image then normalizes data\n",
    "        for b, num in enumerate(nums):\n",
    "            data = pd.read_csv(folder + \"/%06d.csv\" % (num)) # load data from file\n",
    "            data_im = (data.values[:,1:]-np.min(data.values[:,1:])).transpose()\n",
    "            data_im = data_im*255/np.max(data_im)\n",
    "\n",
    "            img = Image.fromarray(data_im)\n",
    "            img = img.convert('RGB')\n",
    "            img_resized = img.resize(dim) # necessary for Inception module\n",
    "\n",
    "            exp_images[num] = data_im # keep unconverted data for reference\n",
    "            exp_num_chem[num] = chem # keep reference of chemical\n",
    "            exp_data[num] = np.array(img_resized)*255/np.max(img_resized)\n",
    "            exp_num.append(num)\n",
    "            train_im.append(img_resized)\n",
    "            train_data.append(np.array(img_resized)*255/np.max(img_resized))\n",
    "            labels.append(chem) # create labels\n",
    "\n",
    "            # update the bar\n",
    "            sys.stdout.write('\\r')\n",
    "            bar = ((b+1)*100)/len(nums)\n",
    "            # the exact output you're looking for:\n",
    "            sys.stdout.write(chem + \": [%-20s] %d%%\" % ('='*int(bar/5-1) + str(int(bar % 10)), bar))\n",
    "            sys.stdout.flush()\n",
    "            loaded += 1\n",
    "\n",
    "        # update the bar\n",
    "        sys.stdout.write(\"   \" + str(count+1) + \"/\" + str(len(exp_set)) + \" complete\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "\n",
    "    exp_set_size = loaded\n",
    "    print(\"Length of experimental set loaded: \" + str(exp_set_size))\n",
    "    \n",
    "    return (train_data, labels, exp_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
