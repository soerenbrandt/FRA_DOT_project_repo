{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning using InceptionV3\n",
    "Inception is an image processing deep learning tool combining trained on ImageNet (https://cloud.google.com/tpu/docs/inception-v3-advanced). Here, we use the fully trained InceptionV3 module to create transfer data from unseen, untrained images to utilize the feature extraction capabilities of Inception without the need to collect sufficient data to train the neural network.\n",
    "\n",
    "We subsequently train a support vector classification (SVM) algorithm on the transfer values from Inception to differentiate different types of images (the transfer values are extracted at the last, red layer on the right of InceptionV3).\n",
    "\n",
    "<img src=https://cloud.google.com/tpu/docs/images/inceptionv3onc--oview.png width = 600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Feb 24 17:41 2019\n",
    "\n",
    "@author: Soeren Brandt\n",
    "\"\"\"\n",
    "# import some generally useful modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import modules for Inception\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experimental image data\n",
    "This is a sample set of exp. data containing 11 classes and 77 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dictionary\n",
    "exp_set = OrderedDict([('C1', [148, 174, 202, 203, 239, 240, 241, 434, 435]),\n",
    "                       ('C2', [175, 184, 185, 186, 187, 199, 204, 205, 424, 425]),\n",
    "                       ('C3', [150, 206, 207]),\n",
    "                       ('C4', [151, 177, 208, 209, 242, 243, 244, 283]),\n",
    "                       ('C5', [152, 178, 188, 189, 267]),\n",
    "                       ('C6', [153, 179, 190, 191, 197, 268, 284]),\n",
    "                       ('C7', [157, 171, 324, 330, 440, 441, 442]),\n",
    "                       ('C8', [169, 170, 312, 313, 443, 444, 445]),\n",
    "                       ('C9', [159, 160, 326, 327, 436, 437, 438, 439]),\n",
    "                       ('C10', [154, 181, 446, 447, 448, 449, 450]),\n",
    "                       ('C11', [163, 164, 452, 453, 454])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading\n",
    "Here, images are loaded from experimental data stored in CSV files. Alternative, (grayscale) photographs can be loaded instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_preparation_for_ML-toolbox import load_images_from_CSV\n",
    "load_images_from_CSV(exp_set, dim = 299, folder='../exp_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalization\n",
    "Data normalization is an important step in machine learning. Here, we linear normalization of the image data to obtain values ranging from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    \"\"\"\n",
    "    Linear normalization\n",
    "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
    "    \"\"\"\n",
    "    arr = arr.astype('float')\n",
    "    minval = arr[...,0].min()\n",
    "    maxval = arr[...,0].max()\n",
    "    if minval != maxval:\n",
    "        # shift values into the range from 0 to 1\n",
    "        arr[...,0] -= minval\n",
    "        arr[...,0] *= (1.0/(maxval-minval))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Inception modele\n",
    "We extract the feature extraction module (left dashed box on top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\"\n",
    "\n",
    "# Create the module, and check the expected image size\n",
    "def feature_extractor(x):\n",
    "    feature_extractor_module = hub.Module(feature_extractor_url)\n",
    "    return feature_extractor_module(x)\n",
    "\n",
    "IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\n",
    "\n",
    "# we just need the Inception v3 layer\n",
    "features_extractor_layer = layers.Lambda(feature_extractor, input_shape=IMAGE_SIZE+[3])\n",
    "model = tf.keras.Sequential([features_extractor_layer])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "sess = K.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature extraction and visualization using t-SNE\n",
    "t-distributed stochastic neighbor embedding (t-SNE) constructs a probability distribution that two parameters are in close proximity in high-dimensional space and then produces a lower-dimensional representation of the proximity map. Similar to principal component analysis, this can be used to display high-dimensional data more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Extract transfer_values from InceptionV3\n",
    "transfer_value = model.predict(train_data)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=np.min([exp_set_size, 67]))\n",
    "transfer_values_50d = pca.fit_transform(transfer_value)\n",
    "\n",
    "# Apply t-SNE after PCA\n",
    "tsne = TSNE(n_components=2)\n",
    "transfer_values_reduced = tsne.fit_transform(transfer_values_50d)\n",
    "\n",
    "# Plot t-SNE\n",
    "%matplotlib inline\n",
    "for chem in set(labels):\n",
    "    plt.plot(transfer_values_reduced.transpose()[0][np.array(labels) == chem],transfer_values_reduced.transpose()[1][np.array(labels) == chem],'.',markersize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform machine learning cross-validation using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_img = transfer_value\n",
    "data_label = labels\n",
    "\n",
    "# Splitting data set into training and testing\n",
    "train_img, test_img, train_lbl, test_lbl = train_test_split(data_img, data_label, test_size=1/2.5, random_state=0)\n",
    "\n",
    "# Training support vector machine\n",
    "SVC = svm.SVC(C=1e2,gamma=1e-2, kernel='rbf')\n",
    "SVC.fit(train_img, train_lbl)\n",
    "predicted = SVC.predict(test_img)\n",
    "\n",
    "print(\"Training accuracy: \" + str(SVC.score(train_img, train_lbl)) + \" (\" + str(len(train_lbl)) + \")\")\n",
    "print(\"Validation accuracy: \" + str(np.sum(predicted == test_lbl)/float(len(test_lbl))) + \" (\" + str(np.sum(predicted == test_lbl)) + \"/\" + str(len(test_lbl)) + \")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
